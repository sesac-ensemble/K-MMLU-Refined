# K-MMLU 벤치마크 성능 향상 프로젝트 (25/10/20 - 25/10/31)

## 📌 프로젝트 개요
제한된 리소스(L4/A100 GPU)와 시간(1주일) 내에서 **K-MMLU(한국어 다중 과제 이해) 벤치마크** 성능을 극대화하는 것을 목표로 한 프로젝트입니다. 다양한 LLM 비교 후 `skt/A.X-4.0-Light`를 베이스 모델로 선정하여 최적화 및 튜닝을 진행했습니다.

<br />

## 🏆 최종 성과
**오답 기반 CoT Instruction Tuning** 전략을 통해 5-shot 베이스라인 대비 **7.8%p** 성능 향상을 달성했습니다.

<br />

| 구분 | 모델 (7B) | 방식 | 정확도 (Accuracy) | 비고 |
|:---:|:---:|:---:|:---:|:---:|
| **Baseline** | skt/A.X-4.0-Light | Zero-shot | 56.25% | 베이스 선정 |
| **Reference**| skt/A.X-4.0-Light | 5-shot (No Tuning) | 51.03% | 비교군 |
| **Final** | **skt/A.X-4.0-Light** | **오답 CoT Tuning** | **58.83%** | **Best (+7.8%p)** |

<br />

## 🔑 핵심 접근 방식
1.  **오답 기반 CoT Instruction Tuning (Main Strategy)**
    * 5-shot 평가 수행 후 오답 데이터 추출 및 K-means 클러스터링(100개).
    * 대표 오답 유형에 대한 Chain-of-Thought(CoT) 데이터 생성 및 학습.
    * 전체 오답 데이터의 약 0.58%(17,155개 중 일부)만 활용하여 효율적 성능 개선 달성.
2.  **Unsloth 적용**
    * QLoRA 4bit 양자화를 통해 학습 속도 31.1% 향상 및 추론 메모리 20% 절감.
3.  **취약 과목 SFT**
    * 평균 점수 하위 과목(Math, History 등) 집중 학습을 통한 보완.

<br />

## 👥 팀원 (Team 2)
이아민, 이지현, 장용석, 허재정
