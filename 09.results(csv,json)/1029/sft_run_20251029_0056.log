ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
í‰ê°€ ëŒ€ìƒ subset ìˆ˜: 11 â†’ ['Accounting', 'Criminal-Law', 'Economics', 'Education', 'Law', 'Management', 'Political-Science-and-Sociology', 'Psychology', 'Social-Welfare', 'Taxation', 'Korean-History']

============================================================
ëª¨ë¸ ë¡œë”© ì¤‘: results/lora_ft_Qwen2.5-7B-Instruct
============================================================

[Unsloth ëª¨ë“œ] FastLanguageModel ë¡œë“œ...
==((====))==  Unsloth 2025.10.6: Fast Qwen2 patching. Transformers: 4.57.1.
   \\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 21.964 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Unsloth ëª¨ë¸ ë¡œë”© ì™„ë£Œ
[LoRA] Unsloth Fast PEFT ì£¼ì…
LoRA ì ìš© ì™„ë£Œ
FlashAttention2 ë¯¸ì§€ì› â†’ ê¸°ë³¸ ëª¨ë“œ
[GPU-MEM] ë¡œë“œ í›„: 7168.1MB / 22491.2MB
ì´ë¯¸ LoRA ì–´ëŒ‘í„°ê°€ ì ìš©ëœ ëª¨ë¸ì…ë‹ˆë‹¤. ì¤‘ë³µ ë¡œë”©ì„ ê±´ë„ˆëœë‹ˆë‹¤.

[ë©”ëª¨ë¦¬] ëª¨ë¸ ë¡œë”© ì™„ë£Œ. ìµœëŒ€ VRAM ì‚¬ìš©ëŸ‰: 6.75 GB

Accounting: 0.6000 (27/45)
Criminal-Law: 0.5059 (43/85)
Economics: 0.5532 (52/94)
Education: 0.5000 (1/2)
Law: 0.5628 (730/1297)
[GPU-MEM] eval Management step | Allocated: 6915.9MB | Reserved: 9426.0MB | Free: 12807.1MB / Total: 22491.2MB
Management: 0.7250 (994/1371)
[GPU-MEM] eval Political-Science-and-Sociology step | Allocated: 6915.9MB | Reserved: 9426.0MB | Free: 12807.1MB / Total: 22491.2MB
Political-Science-and-Sociology: 0.7273 (32/44)
Psychology: 0.7134 (966/1354)
[GPU-MEM] eval Social-Welfare step | Allocated: 6915.9MB | Reserved: 9426.0MB | Free: 12807.1MB / Total: 22491.2MB
Social-Welfare: 0.8015 (727/907)
[GPU-MEM] eval Taxation step | Allocated: 6915.9MB | Reserved: 9426.0MB | Free: 12807.1MB / Total: 22491.2MB
Taxation: 0.3333 (5/15)
Korean-History: 0.0000 (0/1)

[ë©”ëª¨ë¦¬] ì¶”ë¡  ì™„ë£Œ. ìµœëŒ€ VRAM ì‚¬ìš©ëŸ‰: 7.15 GB

============================================================
ë¶„ì•¼ë³„ í‰ê·  ì •í™•ë„
------------------------------------------------------------
Category
HUMSS   0.5475
------------------------------------------------------------
ì „ì²´ í‰ê·  ì •í™•ë„: 0.6859 (3577/5215)
ì´ ì†Œìš” ì‹œê°„: 0:11:00.493041
============================================================
=== CSV ì €ì¥ ì™„ë£Œ: kmmlu_lora_ft_Qwen2.5-7B-Instruct_20251029_010313.csv
=== JSON ì €ì¥ ì™„ë£Œ: kmmlu_lora_ft_Qwen2.5-7B-Instruct_20251029_010313_summary.json
