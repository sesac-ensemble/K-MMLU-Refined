#!/usr/bin/env python
# -*- coding: utf-8 -*-
# run_kmmlu_solar_kowikiQA_opt4.py
"""
KoWikiQA SFT + KMMLU í‰ê°€ (ì˜¤ë¥˜ ìˆ˜ì • + ì•ˆì • ë²„ì „)
- ì •í™•ë„ ê³„ì‚°: all_correct / all_total
- KMMLU 45ê°œ subset ë° supercategory(4ì¢…) ì™„ì „ ë§¤í•‘
- Few-shot ë°©ì‹ ì„ íƒ: --use_manual_fewshots (ê¸°ë³¸=False â†’ devì—ì„œ ëœë¤ 5ê°œ)
- KoWikiQA í•™ìŠµ ë°ì´í„°: ëª¨ë“  train split ëª…ì‹œì  ë³‘í•© + --max_train_samplesë¡œ ì œí•œ
- Robust: tokenizer/FlashAttention/bfloat16/ë°ì´í„° í•„ë“œ/í† í° ì¸ë±ì‹± ì•ˆì „ ì²˜ë¦¬
"""

import os
import re
import time
import random
import argparse
from datetime import datetime

import torch
import pandas as pd
from tqdm import tqdm
from datasets import load_dataset, concatenate_datasets

from unsloth import FastLanguageModel
from transformers import TrainingArguments
from trl import SFTTrainer
from peft import LoraConfig


# =========================================================
# ìˆ˜ë™ 5-shot ì˜ˆì‹œ (ì˜µì…˜ìœ¼ë¡œ ì‚¬ìš©)
# =========================================================
MANUAL_FEWSHOTS = [
    {"question": "ë°˜ë„ì²´ì—ì„œ ì „ìê°€ ì´ë™í•˜ëŠ” ì£¼ìš” ê²½ë¡œëŠ” ë¬´ì—‡ì¸ê°€?", "A": "ì›ìí•µ", "B": "ì „ë„ëŒ€", "C": "ê°€ì „ìëŒ€", "D": "ì ˆì—°ì¸µ", "answer": "2"},
    {"question": "í˜•ë²•ìƒ 'ê³ ì˜'ì˜ ì˜ë¯¸ëŠ” ë¬´ì—‡ì¸ê°€?", "A": "ê²°ê³¼ ë°œìƒì„ ì˜ˆê²¬í•˜ì§€ ëª»í•¨", "B": "ê²°ê³¼ ë°œìƒì„ ì›í•˜ê±°ë‚˜ ìš©ì¸í•¨", "C": "ë‹¨ìˆœí•œ ê³¼ì‹¤", "D": "ì˜ë¬´ ìœ„ë°˜ì— ëŒ€í•œ ë¬´ì§€", "answer": "2"},
    {"question": "íŒ¨ì…˜ íŠ¸ë Œë“œê°€ ìˆœí™˜ì ìœ¼ë¡œ ë°˜ë³µë˜ëŠ” í˜„ìƒì„ ë¬´ì—‡ì´ë¼ í•˜ëŠ”ê°€?", "A": "íŒ¨ì…˜ ì‚¬ì´í´", "B": "íŒ¨ì…˜ ëª¨ë“ˆ", "C": "íŒ¨ì…˜ ë¸”ë Œë“œ", "D": "íŒ¨ì…˜ ì„¸ê·¸ë¨¼íŠ¸", "answer": "1"},
    {"question": "ì¬ë‚œ ëŒ€ì‘ ë‹¨ê³„ ì¤‘ í˜„ì¥ì§€íœ˜ì²´ê³„ë¥¼ êµ¬ì„±í•˜ëŠ” ì£¼ì²´ëŠ”?", "A": "ì¤‘ì•™ì •ë¶€", "B": "ì§€ë°©ìì¹˜ë‹¨ì²´ì¥", "C": "ì†Œë°©ë³¸ë¶€ì¥", "D": "ê²½ì°°ì²­ì¥", "answer": "2"},
    {"question": "ì„¸í¬ ë‚´ ì—ë„ˆì§€ ìƒì„±ì˜ ì£¼ìš” ê¸°ê´€ì€?", "A": "í•µ", "B": "ë¯¸í† ì½˜ë“œë¦¬ì•„", "C": "ë¦¬ë³´ì†œ", "D": "ì†Œí¬ì²´", "answer": "2"},
]


# =========================================================
# ëª¨ë¸ ë° LoRA ìœ í‹¸
# =========================================================
def _is_bf16_supported() -> bool:
    return torch.cuda.is_available() and hasattr(torch.cuda, "is_bf16_supported") and torch.cuda.is_bf16_supported()


def load_unsloth_model(model_id: str, max_seq_length: int = 4096, use_flash_attn2: bool = True):
    print(f"\n{'='*60}\nëª¨ë¸ ë¡œë”© ì¤‘: {model_id}\n{'='*60}\n")
    dtype = torch.bfloat16 if _is_bf16_supported() else torch.float16
    model, tokenizer = FastLanguageModel.from_pretrained(
        model_name=model_id,
        max_seq_length= max_seq_length,
        dtype=dtype,
        load_in_4bit=True,
    )
    # FlashAttention2 (ë¯¸ì§€ì› í™˜ê²½ graceful fallback)
    try:
        FastLanguageModel.for_inference(model, use_flash_attention_2=use_flash_attn2)
        print("FlashAttention2 í™œì„±í™”ë¨")
    except Exception:
        print("FlashAttention2 ë¯¸ì§€ì› í™˜ê²½ â€” ê¸°ë³¸ ëª¨ë“œë¡œ ë¡œë“œ")

    # í† í¬ë‚˜ì´ì € íŒ¨ë”©/í† í° ì„¸ì´í”„ê°€ë“œ
    try:
        tokenizer.padding_side = "left"
    except Exception:
        pass
    if getattr(tokenizer, "pad_token", None) is None and getattr(tokenizer, "eos_token", None) is None:
        # ì–´ë–¤ í† í¬ë‚˜ì´ì €ëŠ” eos/pad ëª¨ë‘ ì—†ìŒ â†’ ì„ì‹œ ì„¸íŒ…
        tokenizer.add_special_tokens({"eos_token": "</s>", "pad_token": "<pad>"})
        model.resize_token_embeddings(len(tokenizer))
    if getattr(tokenizer, "pad_token", None) is None and getattr(tokenizer, "eos_token", None) is not None:
        tokenizer.pad_token = tokenizer.eos_token
    elif getattr(tokenizer, "pad_token", None) is None:
        tokenizer.pad_token = "<pad>"

    model.eval()
    return model, tokenizer


def inject_lora(model, r: int = 8, alpha: int = 16, dropout: float = 0.05):
    cfg = LoraConfig(
        r=r, lora_alpha=alpha, lora_dropout=dropout, bias="none", task_type="CAUSAL_LM"
    )
    model = FastLanguageModel.get_peft_model(model, cfg)
    print(f"LoRA ì£¼ì… ì™„ë£Œ (r={r}, Î±={alpha}, dropout={dropout})")
    return model


# =========================================================
# ë©”ì¸ íŒŒì´í”„ë¼ì¸
# =========================================================
class KoWikiQA2KMMLU:
    def __init__(
        self,
        model_id: str,
        dataset_id: str,
        batch_size: int = 2,
        seed: int = 42,
        use_flash_attn2: bool = True,
        use_manual_fewshots: bool = False,     # ê¸°ë³¸ê°’: ë²¤ì¹˜ë§ˆí¬ ì¼ë°˜ ê´€í–‰(ëœë¤ dev 5-shot)
        max_train_samples: int = 10000,
    ):
        self.model_id = model_id
        self.dataset_id = dataset_id
        self.batch_size = batch_size
        self.seed = seed
        self.use_flash_attn2 = use_flash_attn2
        self.use_manual_fewshots = use_manual_fewshots
        self.max_train_samples = max_train_samples

        random.seed(seed)
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)

        self.model, self.tokenizer = load_unsloth_model(model_id, use_flash_attn2=use_flash_attn2)
        self.subsets = self._get_official_subsets()
        self.supercats = self._get_supercategories()

    # -----------------------------
    # SFT í•™ìŠµ
    # -----------------------------
    def train_on_kowikiQA(self):
        print("\nKoWikiQA ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
        ds = load_dataset(self.dataset_id)

        # ëª¨ë“  train split ëª…ì‹œì ìœ¼ë¡œ ë³‘í•©
        trains = []
        for k in ds.keys():
            if "train" in k.lower():
                trains.append(ds[k])
        if not trains:
            # ì˜ˆì™¸ì ìœ¼ë¡œ split ì´ë¦„ì´ trainì´ ì•„ë‹Œ ê²½ìš° ì „ì²´ ë³‘í•©
            trains = [ds[k] for k in ds.keys()]
        merged = concatenate_datasets(trains) if len(trains) > 1 else trains[0]

        # ê°œìˆ˜ ì œí•œ
        use_n = min(self.max_train_samples, len(merged))
        train_ds = merged.select(range(use_n))
        print(f"í•™ìŠµ ë°ì´í„° ê°œìˆ˜: {len(train_ds)} ì‚¬ìš©")

        # í¬ë§· ë³€í™˜ (í•„ë“œ ì•ˆì „ ì ‘ê·¼)
        def fmt(ex):
            q = ex.get("instruction", "")
            a = ex.get("output", "")
            return {"text": f"ì§ˆë¬¸: {q}\në‹µë³€: {a}"}

        train_ds = train_ds.map(fmt, remove_columns=[c for c in train_ds.column_names if c != "text"])

        # LoRA ì£¼ì…
        self.model = inject_lora(self.model)

        args = TrainingArguments(
            output_dir="results/lora_kowikiQA",
            num_train_epochs=1,
            per_device_train_batch_size=1,
            gradient_accumulation_steps=4,
            learning_rate=2e-5,
            warmup_ratio=0.03,
            logging_steps=10,
            save_steps=1000,
            report_to="none",
        )
        trainer = SFTTrainer(model=self.model, tokenizer=self.tokenizer, train_dataset=train_ds, args=args)
        print("\nğŸš€ SFT í•™ìŠµ ì‹œì‘...")
        trainer.train()
        os.makedirs("results/lora_kowikiQA", exist_ok=True)
        trainer.save_model("results/lora_kowikiQA")
        print("SFT í•™ìŠµ ì™„ë£Œ ë° LoRA ê°€ì¤‘ì¹˜ ì €ì¥ ì™„ë£Œ.")

    # -----------------------------
    # Few-shot ìƒì„±
    # -----------------------------
    def _get_fewshots(self, subset: str):
        """--use_manual_fewshotsê°€ Falseë©´ dev/validationì—ì„œ 5ê°œ ëœë¤ ì‚¬ìš©"""
        if self.use_manual_fewshots:
            return MANUAL_FEWSHOTS

        try:
            ds = load_dataset("HAERAE-HUB/KMMLU", subset)
            candidates = None
            for sp in ["dev", "validation", "test", "train"]:
                if sp in ds:
                    candidates = list(ds[sp])
                    break
            if not candidates:
                return MANUAL_FEWSHOTS

            # ì •ë‹µì´ 1~4ë¡œ ì¡´ì¬í•˜ëŠ” ê²ƒë§Œ í›„ë³´
            valid = [ex for ex in candidates if ex.get("answer") in [1, 2, 3, 4, "1", "2", "3", "4"]]
            if not valid:
                return MANUAL_FEWSHOTS

            k = min(5, len(valid))
            return random.sample(valid, k)
        except Exception as e:
            print(f"Few-shot ìƒì„± ì‹¤íŒ¨({subset}): {e}")
            return MANUAL_FEWSHOTS

    # -----------------------------
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    # -----------------------------
    @staticmethod
    def _norm(t): 
        return re.sub(r"\s+", " ", str(t)).strip()

    def _make_prompt(self, ex, fewshots):
        prompt = ""
        for fs in fewshots:
            prompt += f"ë¬¸ì œ: {self._norm(fs.get('question',''))}\n"
            for c in ["A", "B", "C", "D"]:
                prompt += f"{c}. {self._norm(fs.get(c,''))}\n"
            prompt += f"ì •ë‹µ: {fs.get('answer','')}\n\n"
        prompt += f"ë¬¸ì œ: {self._norm(ex.get('question',''))}\n"
        for c in ["A", "B", "C", "D"]:
            prompt += f"{c}. {self._norm(ex.get(c,''))}\n"
        prompt += "ì •ë‹µ: "
        return prompt

    # -----------------------------
    # ì •ë‹µ ì²˜ë¦¬ (KMMLU: 1/2/3/4 â†’ 0~3)
    # -----------------------------
    @staticmethod
    def _extract_answer_index(ex):
        ans = ex.get("answer")
        if isinstance(ans, int):
            return ans - 1 if 1 <= ans <= 4 else None
        if isinstance(ans, str) and ans.isdigit():
            n = int(ans)
            return n - 1 if 1 <= n <= 4 else None
        return None

    # -----------------------------
    # ë§ˆì§€ë§‰ í† í° ë¡œì§“ì—ì„œ ABCD ì²« í† í°ë§Œ ë¹„êµ
    # -----------------------------
    def _predict_logits(self, inputs):
        with torch.no_grad():
            logits = self.model(**inputs).logits[:, -1, :]
        choice_ids = []
        for ch in ["A", "B", "C", "D"]:
            toks = self.tokenizer.encode(ch, add_special_tokens=False)
            choice_ids.append(toks[0] if toks else 0)
        preds = torch.argmax(logits[:, choice_ids], dim=-1)
        return preds.cpu().tolist()

    # -----------------------------
    # KMMLU í‰ê°€
    # -----------------------------
    def evaluate_kmmlu(self):
        results = []
        all_correct = 0
        all_total = 0
        start = time.time()

        for subset in tqdm(self.subsets, desc="KMMLU ì „ì²´ í‰ê°€"):
            try:
                dataset = load_dataset("HAERAE-HUB/KMMLU", subset)

                test = None
                for split in ["test", "validation", "dev", "train"]:
                    if split in dataset:
                        test = list(dataset[split])
                        break
                if not test:
                    print(f"{subset}: í‰ê°€ ê°€ëŠ¥í•œ split ì—†ìŒ â†’ skip")
                    continue

                # ìœ íš¨ ì •ë‹µë§Œ í•„í„°
                test = [ex for ex in test if ex.get("answer") in [1, 2, 3, 4, "1", "2", "3", "4"]]
                if not test:
                    print(f"{subset}: ìœ íš¨ ì •ë‹µ ì—†ìŒ â†’ skip")
                    continue

                fewshots = self._get_fewshots(subset)

                prompts = [self._make_prompt(t, fewshots) for t in test]
                truths = [self._extract_answer_index(t) for t in test]
                correct = total = 0

                for i in range(0, len(prompts), self.batch_size):
                    batch = prompts[i:i+self.batch_size]
                    truth = truths[i:i+self.batch_size]
                    inputs = self.tokenizer(batch, return_tensors="pt", padding=True, truncation=True, max_length=3072).to(self.model.device)
                    preds = self._predict_logits(inputs)
                    for p, t in zip(preds, truth):
                        if t is not None:
                            total += 1
                            if p == t:
                                correct += 1

                acc = correct / total if total else 0.0
                print(f"{subset}: {acc:.4f} ({correct}/{total})")
                results.append({
                    "Subset": subset,
                    "SuperCategory": self.supercats.get(subset, "Unknown"),
                    "Accuracy": acc
                })
                all_correct += correct
                all_total += total

            except Exception as e:
                print(f"{subset} ì˜¤ë¥˜: {e}")
                import traceback; traceback.print_exc()
                results.append({"Subset": subset, "SuperCategory": self.supercats.get(subset, "Unknown"), "Accuracy": 0.0})

        # ì €ì¥ ë° ìš”ì•½
        os.makedirs("results", exist_ok=True)
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        out_csv = f"results/kowikiQA2KMMLU_opt4_{ts}.csv"
        pd.DataFrame(results).to_csv(out_csv, index=False, encoding="utf-8-sig")

        overall_acc = (all_correct / all_total) if all_total else 0.0
        print(f"\nì „ì²´ í‰ê· : {overall_acc:.4f} ({all_correct}/{all_total})")
        print(f"CSV ì €ì¥ ì™„ë£Œ â†’ {out_csv}")
        print(f"ì´ ê²½ê³¼ì‹œê°„: {(time.time()-start)/60:.1f}ë¶„")

        # SuperCategoryë³„ í‰ê· ë„ í•¨ê»˜ ì¶œë ¥
        try:
            df = pd.DataFrame(results)
            sc_df = df.groupby("SuperCategory", as_index=False)["Accuracy"].mean().sort_values("Accuracy", ascending=False)
            out_csv_sc = f"results/kowikiQA2KMMLU_opt4_supercats_{ts}.csv"
            sc_df.to_csv(out_csv_sc, index=False, encoding="utf-8-sig")
            print("\n[SuperCategory í‰ê·  ì •í™•ë„]")
            print(sc_df.to_string(index=False))
            print(f"SuperCategory CSV ì €ì¥ â†’ {out_csv_sc}")
        except Exception as e:
            print(f"SuperCategory í‰ê·  ê³„ì‚° ì‹¤íŒ¨: {e}")

    # =====================================================
    # KMMLU Subsets & SuperCategories
    # =====================================================
    @staticmethod
    def _get_official_subsets():
        # ê³µì‹ 45ê°œ êµ¬ì„±
        return [
            "Accounting", "Agricultural-Sciences", "Aviation-Engineering-and-Maintenance", "Biology",
            "Chemical-Engineering", "Chemistry", "Civil-Engineering", "Computer-Science", "Construction",
            "Criminal-Law", "Ecology", "Economics", "Education", "Electrical-Engineering",
            "Electronics-Engineering", "Energy-Management", "Environmental-Science", "Fashion",
            "Food-Processing", "Gas-Technology-and-Engineering", "Geomatics", "Health", "Industrial-Engineer",
            "Information-Technology", "Interior-Architecture-and-Design", "Law", "Machine-Design-and-Manufacturing",
            "Management", "Maritime-Engineering", "Marketing", "Materials-Engineering", "Mechanical-Engineering",
            "Nondestructive-Testing", "Patent", "Political-Science-and-Sociology", "Psychology",
            "Public-Safety", "Railway-and-Automotive-Engineering", "Real-Estate", "Refrigerating-Machinery",
            "Social-Welfare", "Taxation", "Telecommunications-and-Wireless-Technology",
            "Korean-History", "Math"
        ]

    @staticmethod
    def _get_supercategories():
        cats = {
            "STEM": [
                "Biology", "Chemical-Engineering", "Chemistry", "Civil-Engineering",
                "Computer-Science", "Ecology", "Electrical-Engineering", "Information-Technology",
                "Materials-Engineering", "Mechanical-Engineering", "Math"
            ],
            "HUMSS": [
                "Accounting", "Criminal-Law", "Economics", "Education",
                "Law", "Management", "Political-Science-and-Sociology",
                "Psychology", "Social-Welfare", "Taxation", "Korean-History"
            ],
            "Applied Science": [
                "Aviation-Engineering-and-Maintenance", "Electronics-Engineering", "Energy-Management",
                "Environmental-Science", "Gas-Technology-and-Engineering", "Geomatics",
                "Industrial-Engineer", "Machine-Design-and-Manufacturing", "Maritime-Engineering",
                "Nondestructive-Testing", "Railway-and-Automotive-Engineering",
                "Telecommunications-and-Wireless-Technology"
            ],
            "Other": [
                "Agricultural-Sciences", "Construction", "Fashion", "Food-Processing", "Health",
                "Interior-Architecture-and-Design", "Marketing", "Patent", "Public-Safety",
                "Real-Estate", "Refrigerating-Machinery"
            ]
        }
        mapping = {}
        for cat, subs in cats.items():
            for s in subs:
                mapping[s] = cat
        return mapping


# =========================================================
# Main
# =========================================================
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model_id", type=str, default="upstage/SOLAR-10.7B-Instruct-v1.0")
    parser.add_argument("--dataset_id", type=str, default="maywell/ko_wikidata_QA")
    parser.add_argument("--batch_size", type=int, default=2)
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--no_flash_attn2", action="store_true")
    parser.add_argument("--eval_only", action="store_true")
    parser.add_argument("--use_manual_fewshots", action="store_true", help="ìˆ˜ë™ ì˜ˆì‹œ(MANUAL_FEWSHOTS) ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸: ëœë¤ 5-shot)")
    parser.add_argument("--max_train_samples", type=int, default=10000, help="í•™ìŠµ ë°ì´í„° ìµœëŒ€ ê°œìˆ˜ ì œí•œ")
    args = parser.parse_args()

    evaluator = KoWikiQA2KMMLU(
        model_id=args.model_id,
        dataset_id=args.dataset_id,
        batch_size=args.batch_size,
        seed=args.seed,
        use_flash_attn2=not args.no_flash_attn2,
        use_manual_fewshots=args.use_manual_fewshots,
        max_train_samples=args.max_train_samples,
    )

    if not args.eval_only:
        evaluator.train_on_kowikiQA()
    evaluator.evaluate_kmmlu()


if __name__ == "__main__":
    main()


# í•™ìŠµ + í‰ê°€ (ëœë¤ dev 5-shot, 10K ìƒ˜í”Œ í•™ìŠµ)
# python run_kmmlu_solar_kowikiQA_opt4.py \
#   --model_id upstage/SOLAR-10.7B-Instruct-v1.0 \
#   --dataset_id maywell/ko_wikidata_QA \
#   --max_train_samples 10000

# í‰ê°€ë§Œ (ìˆ˜ë™ few-shot ì‚¬ìš©)
# python run_kmmlu_solar_kowikiQA_opt4.py --eval_only --use_manual_fewshots